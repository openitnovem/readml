{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d4484f-927e-4619-8938-a689b21759bf",
   "metadata": {},
   "source": [
    "# Computer Vision for image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7039090-8af8-43d4-8c4c-85b0158c8c8f",
   "metadata": {},
   "source": [
    "**Author**: Jonathan TRICARD\n",
    "\n",
    "**Summary**: using a dataset propose by keras, we build a VGG16 model to predict if the images are apple or fish (class 0 or 1). Then, we try to use the Grad Cam method to explain the choice of the model.\n",
    "\n",
    "**ExplainDL**: create a ```.jpg``` file for each image in the selected path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a36f659-bb27-42d9-ad4f-5b4f93d4e730",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c00929-2078-4396-b109-d0ba30149b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from readml.explainers.dl.explain_dl import ExplainDL\n",
    "from readml.logger import ROOT_DIR\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e603c764-d61e-45db-8094-e8a525fdc502",
   "metadata": {},
   "source": [
    "## Initialize the directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce36de2-a562-4b15-863b-0a731fa6030e",
   "metadata": {},
   "source": [
    "This step is specific to the image classification. We need to create a structure, to save our image data and use it in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550d84b-4582-4d1f-8414-fe66ed828772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_directories_dl(out_path, dir_to_create):\n",
    "    os.chdir(ROOT_DIR)\n",
    "    new_root = os.getcwd()\n",
    "    new_root = \"/\".join(new_root.split(\"/\")[:-1])\n",
    "    os.chdir(new_root)\n",
    "    start = out_path.index(\"/\") + 1\n",
    "    split = out_path[start:].split(\"/\")\n",
    "    for elt in split:\n",
    "        if not os.path.isdir(elt):\n",
    "            os.makedirs(elt)\n",
    "            os.chdir(elt)\n",
    "        else:\n",
    "            os.chdir(elt)\n",
    "    os.chdir(ROOT_DIR)\n",
    "\n",
    "    for elt in dir_to_create:\n",
    "        if not os.path.isdir(os.path.join(out_path, elt)):\n",
    "            os.makedirs(os.path.join(out_path, elt))\n",
    "\n",
    "\n",
    "def create_dir_image():\n",
    "    dir_to_create = [\"data_image\", \"image\"]\n",
    "    out_path = \"../outputs/notebooks/dl\"\n",
    "    initialize_directories_dl(out_path, dir_to_create)\n",
    "\n",
    "\n",
    "create_dir_image()\n",
    "data_image_path = os.path.join(ROOT_DIR, \"../outputs/notebooks/dl\", \"data_image\")\n",
    "output_path_image_dir = os.path.join(ROOT_DIR, \"../outputs/notebooks/dl\", \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7713b035-0fdd-4397-b5b5-34f0bb168365",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d6826-977e-4f82-82d4-3c6009767e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_data_rgb():\n",
    "    (train_images, train_labels), (\n",
    "        test_images,\n",
    "        test_labels,\n",
    "    ) = tf.keras.datasets.cifar100.load_data(label_mode=\"fine\")\n",
    "    _, width, height, channel = train_images.shape\n",
    "    # Focus on two labels\n",
    "    focus = list(itertools.chain(*train_labels))\n",
    "    focus_0_1 = [\n",
    "        index for index, value in enumerate(focus) if value == 0 or value == 1\n",
    "    ][0:10]\n",
    "    train_images = train_images[focus_0_1]\n",
    "    train_labels = np.array(\n",
    "        [elt[0] for idx, elt in enumerate(train_labels) if idx in focus_0_1]\n",
    "    )\n",
    "    return train_images, train_labels, width, height, channel\n",
    "\n",
    "def save_image_data(X_train, name):  # data_image_path\n",
    "    for idx, img in enumerate(X_train):\n",
    "        cv2.imwrite(os.path.join(data_image_path, f\"{name}_{idx+1}.jpg\"), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a187a434-01a0-4c36-97ed-568631eed8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, width, height, channel = create_image_data_rgb()\n",
    "save_image_data(X_train, \"cifar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b9806-33ba-4d48-951d-22a8709afa99",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7c12e0-c659-4df0-82b1-83d84fb0c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model_image_rgb(X_train, y_train, width, height, channel):\n",
    "    baseModel = VGG16(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        input_tensor=Input(shape=(width, height, channel)),\n",
    "    )\n",
    "    headModel = baseModel.output\n",
    "    headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(1, activation=\"softmax\")(headModel)\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd3b741-4feb-432a-a35f-3c571641fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_model_image_rgb(X_train, y_train, width, height, channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d3b0e-a9e7-4cff-a643-2a7cc0267864",
   "metadata": {},
   "source": [
    "## Make intelligibility with Grad Cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d58635-c823-4375-9a10-0cea0e154faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model\n",
    "out_path = output_path_image_dir # the path where you want to save the report\n",
    "image_dir = data_image_path # the path of the image\n",
    "size = (width, height) # the size of the pictures\n",
    "color_mode = \"rgb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f0802-c47f-49bf-86af-e19f2d6fb131",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ExplainDL(\n",
    "        model=model,\n",
    "        out_path=out_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a820f01-b6a4-44d4-b862-1ab00aafe739",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.explain_image(\n",
    "        image_dir=image_dir,\n",
    "        size=size,\n",
    "        color_mode=color_mode,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
